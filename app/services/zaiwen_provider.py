import json
import httpx
import uuid
import time
import re
from typing import AsyncGenerator, List, Dict, Any, Optional
from app.core.config import settings
from app.utils.logger import logger
from app.services.account_manager import account_manager


class OutputFilter:
    """æ™ºèƒ½è¾“å‡ºè¿‡æ»¤å™¨ - è¿‡æ»¤AIçš„å†—ä½™ä¿¡æ¯ï¼Œåªä¿ç•™æœ‰ç”¨å†…å®¹"""
    
    # éœ€è¦è¿‡æ»¤çš„æ¨¡å¼åˆ—è¡¨ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
    FILTER_PATTERNS = [
        # ä¼šè¯å…ƒæ•°æ®
        r"^\s*\{'type':\s*'(conversation|user-message|assistant-message)'.*?\}\s*$",
        # æ·±åº¦ç ”ç©¶å¼€å…³æ ‡è®°
        r"^\s*æ·±åº¦ç ”ç©¶:\s*(å¼€å¯|å…³é—­)\s*$",
        # æ¨¡å—æ—¥å¿—
        r"^---\s*æ¨¡å—[\d\.]+.*?---\s*$",
        r"^è¾“å…¥(é—®é¢˜|å…³é”®è¯).*?[:ï¼š].*$",
        r"^(ç½‘ç»œæœç´¢|é‡è¯•å).*?(è¿”å›|ç»“æŸ).*$",
        r"^\s*æ ¸å¿ƒå¾ªç¯.*è½®\s*$",
        # Thinking è¿‡ç¨‹
        r"^\s*\*Thinking\.\.\.\*\s*$",
        r"^>\s*\*\*.*?\*\*\s*$",  # > **Evaluating...**
        r"^>\s*$",  # ç©ºçš„å¼•ç”¨è¡Œ
        r"^>\s*I'm\s+(currently|now|struggling|focusing).*$",  # thinking content
        r"^>\s*I've\s+(been|moved|decided).*$",
        r"^>\s*My\s+(focus|thought|role).*$",
        r"^>\s*The\s+(current|goal|lack|constraints).*$",
        r"^>\s*This\s+(approach|is|ensures).*$",
        # æŠ¥å‘Šç­–ç•¥å¸ˆæ¨¡å—
        r"^æŠ¥å‘Šç­–ç•¥å¸ˆ.*$",
        # HTML ä»£ç å—æ ‡è®°
        r"^```html\s*$",
        r"^```\s*$",
        # å·¥ä½œæµç»Ÿè®¡
        r"^å·¥ä½œæµæ€»è€—æ—¶.*ç§’\s*$",
        # è¯¦ç»†ä¸“ä¸šæŠ¥å‘Šæ ‡è®°ï¼ˆå¯é€‰ï¼Œçœ‹ç”¨æˆ·éœ€æ±‚ï¼‰
        r"^#\s*è¯¦ç»†ä¸“ä¸šæŠ¥å‘Š\s*$",
        r"^æ›´è¯¦ç»†çš„ä¸“ä¸šæŠ¥å‘Šè§ä¸‹æ–‡ã€‚?\s*$",
        # æœ€ç»ˆç­”æ¡ˆè¾“å‡ºæ ‡è®°
        r"^=+\s*æœ€ç»ˆç­”æ¡ˆè¾“å‡º\s*=+\s*$",
        # è®¡åˆ’è·å–ç»“æœè¡Œ
        r"^.*è®¡åˆ’æœ€å¤šè·å–\s*\d+\s*ä¸ªç»“æœ.*$",
    ]
    
    # å¼€å§‹è¯¦ç»†æŠ¥å‘Šçš„æ ‡è®°ï¼ˆä¹‹åçš„å†…å®¹å¯é€‰æ‹©è¿‡æ»¤ï¼‰
    DETAILED_REPORT_START = [
        "# è¯¦ç»†ä¸“ä¸šæŠ¥å‘Š",
        "## 1. æ‰§è¡Œæ‘˜è¦",
    ]
    
    # HTML å†…å®¹æ£€æµ‹
    HTML_PATTERNS = [
        r"<!DOCTYPE\s+html>",
        r"<html\s+lang=",
        r"<head>",
        r"<style>",
        r"<body>",
        r"</html>",
    ]
    
    def __init__(self, filter_detailed_report: bool = True, filter_html: bool = True):
        """
        åˆå§‹åŒ–è¿‡æ»¤å™¨
        
        Args:
            filter_detailed_report: æ˜¯å¦è¿‡æ»¤è¯¦ç»†ä¸“ä¸šæŠ¥å‘Šï¼ˆåªä¿ç•™ç®€æ´ç­”æ¡ˆï¼‰
            filter_html: æ˜¯å¦è¿‡æ»¤HTMLä»£ç å—
        """
        self.filter_detailed_report = filter_detailed_report
        self.filter_html = filter_html
        self._compiled_patterns = [re.compile(p, re.IGNORECASE) for p in self.FILTER_PATTERNS]
        self._html_patterns = [re.compile(p, re.IGNORECASE) for p in self.HTML_PATTERNS]
        
        # çŠ¶æ€è¿½è¸ª
        self._in_detailed_report = False
        self._in_html_block = False
        self._in_thinking_block = False
        self._buffer = ""
    
    def reset(self):
        """é‡ç½®è¿‡æ»¤å™¨çŠ¶æ€"""
        self._in_detailed_report = False
        self._in_html_block = False
        self._in_thinking_block = False
        self._buffer = ""
    
    def _is_json_metadata(self, text: str) -> bool:
        """æ£€æµ‹æ˜¯å¦æ˜¯JSONå…ƒæ•°æ®"""
        stripped = text.strip()
        if stripped.startswith("{") and stripped.endswith("}"):
            try:
                data = json.loads(stripped)
                if isinstance(data, dict):
                    if data.get("type") in ["conversation", "user-message", "assistant-message"]:
                        return True
                    if "conversation_id" in data and "data" in data:
                        return True
            except json.JSONDecodeError:
                pass
        return False
    
    def _should_filter_line(self, line: str) -> bool:
        """æ£€æŸ¥å•è¡Œæ˜¯å¦åº”è¯¥è¢«è¿‡æ»¤"""
        stripped = line.strip()
        
        # ç©ºè¡Œä¿ç•™
        if not stripped:
            return False
        
        # æ£€æµ‹JSONå…ƒæ•°æ®
        if self._is_json_metadata(stripped):
            return True
        
        # HTML å—æ£€æµ‹
        if self.filter_html:
            for pattern in self._html_patterns:
                if pattern.search(stripped):
                    return True
        
        # æ­£åˆ™æ¨¡å¼åŒ¹é…
        for pattern in self._compiled_patterns:
            if pattern.match(stripped):
                return True
        
        return False
    
    def _detect_section_transition(self, line: str) -> Optional[str]:
        """æ£€æµ‹ç« èŠ‚è½¬æ¢ï¼Œè¿”å›æ–°çš„çŠ¶æ€æˆ–None"""
        stripped = line.strip()
        
        # æ£€æµ‹æ˜¯å¦è¿›å…¥è¯¦ç»†æŠ¥å‘Š
        for marker in self.DETAILED_REPORT_START:
            if stripped.startswith(marker):
                return "detailed_report"
        
        # æ£€æµ‹æ˜¯å¦è¿›å…¥thinkingå—
        if stripped == "*Thinking...*":
            return "thinking"
        
        # æ£€æµ‹HTMLå¼€å§‹
        if stripped == "```html":
            return "html_block"
        
        # æ£€æµ‹å—ç»“æŸ
        if stripped == "```" and (self._in_html_block or self._in_thinking_block):
            return "block_end"
        
        return None
    
    def filter_content(self, content: str) -> str:
        """
        è¿‡æ»¤å†…å®¹ï¼Œè¿”å›æ¸…ç†åçš„æ–‡æœ¬
        
        Args:
            content: åŸå§‹å†…å®¹
            
        Returns:
            è¿‡æ»¤åçš„å†…å®¹
        """
        if not content:
            return content
        
        lines = content.split('\n')
        filtered_lines = []
        
        for line in lines:
            # æ£€æµ‹ç« èŠ‚è½¬æ¢
            transition = self._detect_section_transition(line)
            
            if transition == "detailed_report" and self.filter_detailed_report:
                self._in_detailed_report = True
                continue
            elif transition == "thinking":
                self._in_thinking_block = True
                continue
            elif transition == "html_block":
                self._in_html_block = True
                continue
            elif transition == "block_end":
                self._in_html_block = False
                self._in_thinking_block = False
                continue
            
            # å¦‚æœåœ¨éœ€è¦è¿‡æ»¤çš„åŒºå—å†…ï¼Œè·³è¿‡
            if self._in_detailed_report and self.filter_detailed_report:
                continue
            if self._in_html_block and self.filter_html:
                continue
            if self._in_thinking_block:
                # Thinkingå—å†…çš„å¼•ç”¨è¡Œ
                if line.strip().startswith(">"):
                    continue
                # é‡åˆ°éå¼•ç”¨è¡Œï¼Œå¯èƒ½thinkingå—ç»“æŸ
                if line.strip() and not line.strip().startswith(">"):
                    self._in_thinking_block = False
            
            # å•è¡Œè¿‡æ»¤æ£€æŸ¥
            if self._should_filter_line(line):
                continue
            
            filtered_lines.append(line)
        
        return '\n'.join(filtered_lines)
    
    def filter_stream_chunk(self, chunk: str) -> str:
        """
        è¿‡æ»¤æµå¼è¾“å‡ºçš„å•ä¸ªchunk
        
        Args:
            chunk: å•ä¸ªæµå¼chunk
            
        Returns:
            è¿‡æ»¤åçš„chunkï¼ˆå¯èƒ½ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
        """
        # å°†chunkæ·»åŠ åˆ°ç¼“å†²åŒº
        self._buffer += chunk
        
        # æ£€æµ‹æ˜¯å¦æœ‰å®Œæ•´çš„è¡Œå¯ä»¥å¤„ç†
        if '\n' not in self._buffer:
            # æ²¡æœ‰å®Œæ•´è¡Œï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯éœ€è¦è¿‡æ»¤çš„å¼€å§‹æ ‡è®°
            for pattern in self._compiled_patterns:
                if pattern.match(self._buffer.strip()):
                    return ""
            # ä¸ç¡®å®šï¼Œæš‚æ—¶ä¿ç•™
            return chunk
        
        # æœ‰å®Œæ•´è¡Œï¼Œå¤„ç†ç¼“å†²åŒº
        lines = self._buffer.split('\n')
        self._buffer = lines[-1]  # ä¿ç•™ä¸å®Œæ•´çš„æœ€åä¸€è¡Œ
        
        filtered_parts = []
        for line in lines[:-1]:
            filtered = self.filter_content(line)
            if filtered.strip():
                filtered_parts.append(filtered)
        
        if filtered_parts:
            return '\n'.join(filtered_parts) + '\n'
        return ""


class ZaiwenProvider:
    """
    Zaiwen AI Provider with multiple output modes.
    
    Model naming convention:
    - "Model-Name" or "Model-Name (ç®€è¦ç­”æ¡ˆ)" - Concise answer only, stops after concise answer
    - "Model-Name (ä¸“ä¸šæŠ¥å‘Š)" - Full professional report
    - "Model-Name (HTML)" - HTML report output
    """
    
    # æ”¯æŒçš„åŸºç¡€æ¨¡å‹åˆ—è¡¨
    BASE_MODELS = [
        "Gemini-3.0-Flash",
        "GPT-5.2-Instant", 
        "gemini_2_5_flash",
        "gemini_2_5_pro",
        "Grok-4.1-Fast-Non-Reasoning",
        "Grok-4-Fast-Reasoning",
        "claude-sonnet-4",
    ]
    
    # è¾“å‡ºæ¨¡å¼
    OUTPUT_MODE_CONCISE = "concise"      # ç®€è¦ç­”æ¡ˆ
    OUTPUT_MODE_REPORT = "report"        # ä¸“ä¸šæŠ¥å‘Š
    OUTPUT_MODE_HTML = "html"            # HTMLæŠ¥å‘Š
    
    def __init__(self):
        self.base_headers = {
            "Accept": "*/*",
            "Accept-Encoding": "gzip, deflate, br, zstd",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Connection": "keep-alive",
            "Content-Type": "application/json",
            "Origin": "https://www.zaiwenai.com",
            "Referer": "https://www.zaiwenai.com/",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36",
            "channel": "web.zaiwenai.com",
        }
        self.url = f"{settings.ZAIWEN_BASE_URL}/api/v1/ai/message/stream"
    
    def _parse_model_name(self, model: str) -> tuple:
        """
        è§£ææ¨¡å‹åç§°ï¼Œè¿”å› (åŸºç¡€æ¨¡å‹å, è¾“å‡ºæ¨¡å¼)
        
        Examples:
            "Gemini-3.0-Flash" -> ("Gemini-3.0-Flash", "concise")
            "Gemini-3.0-Flash (ç®€è¦ç­”æ¡ˆ)" -> ("Gemini-3.0-Flash", "concise")
            "Gemini-3.0-Flash (ä¸“ä¸šæŠ¥å‘Š)" -> ("Gemini-3.0-Flash", "report")
            "Gemini-3.0-Flash (HTML)" -> ("Gemini-3.0-Flash", "html")
        """
        model = model.strip()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å¼åç¼€
        if model.endswith("(ç®€è¦ç­”æ¡ˆ)"):
            base_model = model.replace("(ç®€è¦ç­”æ¡ˆ)", "").strip()
            return base_model, self.OUTPUT_MODE_CONCISE
        elif model.endswith("(ä¸“ä¸šæŠ¥å‘Š)"):
            base_model = model.replace("(ä¸“ä¸šæŠ¥å‘Š)", "").strip()
            return base_model, self.OUTPUT_MODE_REPORT
        elif model.endswith("(HTML)"):
            base_model = model.replace("(HTML)", "").strip()
            return base_model, self.OUTPUT_MODE_HTML
        else:
            # é»˜è®¤è¿”å›ç®€è¦ç­”æ¡ˆæ¨¡å¼
            return model, self.OUTPUT_MODE_CONCISE

    def _prepare_prompt(self, messages: List[Dict[str, str]]) -> str:
        """Concatenates OpenAI messages into a single prompt string."""
        prompt_parts = []
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            if role == "system":
                prompt_parts.append(f"System: {content}")
            elif role == "user":
                prompt_parts.append(f"User: {content}")
            elif role == "assistant":
                prompt_parts.append(f"Assistant: {content}")
            else:
                prompt_parts.append(f"{role}: {content}")
        return "\n".join(prompt_parts)

    def _construct_payload(self, prompt: str, model: str) -> Dict[str, Any]:
        return {
            "data": {
                "content": prompt,
                "model": model, 
                "round": 5, 
                "type": "deepsearch", 
                "online": True,
                "file": {},
                "knowledge": [],
                "draw": {},
                "suno_input": {},
                "video": {
                    "ratio": "1:1",
                    "original_image": {
                        "image": {},
                        "weight": 50
                    }
                }
            }
        }

    async def chat_completions(
        self, 
        messages: List[Dict[str, str]], 
        model: str
    ) -> AsyncGenerator[str, None]:
        """
        Chat completions with intelligent output mode control.
        
        Model variants:
        - "Model-Name" or "Model-Name (ç®€è¦ç­”æ¡ˆ)" - Stops after concise answer
        - "Model-Name (ä¸“ä¸šæŠ¥å‘Š)" - Full professional report (no HTML)
        - "Model-Name (HTML)" - HTML report only
        """
        # è§£ææ¨¡å‹åç§°è·å–åŸºç¡€æ¨¡å‹å’Œè¾“å‡ºæ¨¡å¼
        base_model, output_mode = self._parse_model_name(model)
        
        prompt = self._prepare_prompt(messages)
        target_model = base_model if base_model else "Gemini-3.0-Flash"
        payload = self._construct_payload(prompt, target_model)
        
        logger.info(f"ğŸ“ [Mode] Output mode: {output_mode} for model: {target_model}")
        
        # æ ¹æ®è¾“å‡ºæ¨¡å¼é…ç½®è¿‡æ»¤å™¨
        if output_mode == self.OUTPUT_MODE_CONCISE:
            # ç®€è¦ç­”æ¡ˆæ¨¡å¼ï¼šè¿‡æ»¤æ‰€æœ‰ï¼Œæ£€æµ‹åˆ°è¯¦ç»†æŠ¥å‘Šå¼€å§‹æ—¶åœæ­¢
            output_filter = OutputFilter(filter_detailed_report=True, filter_html=True)
            stop_at_detailed_report = True
            extract_html_only = False
        elif output_mode == self.OUTPUT_MODE_REPORT:
            # ä¸“ä¸šæŠ¥å‘Šæ¨¡å¼ï¼šä¸è¿‡æ»¤æŠ¥å‘Šï¼Œä½†è¿‡æ»¤HTML
            output_filter = OutputFilter(filter_detailed_report=False, filter_html=True)
            stop_at_detailed_report = False
            extract_html_only = False
        elif output_mode == self.OUTPUT_MODE_HTML:
            # HTMLæ¨¡å¼ï¼šåªæå–HTMLå†…å®¹
            output_filter = None
            stop_at_detailed_report = False
            extract_html_only = True
        else:
            output_filter = OutputFilter(filter_detailed_report=True, filter_html=True)
            stop_at_detailed_report = True
            extract_html_only = False
        
        # 1. Get Dynamic Token
        token = await account_manager.get_token()
        if not token:
            yield f"data: {json.dumps({'error': 'No active tokens available'})}\n\n"
            return

        headers = self.base_headers.copy()
        headers["token"] = token
        
        logger.info(f"ğŸš€ [Token] Using token: {token[:8]}... for model: {target_model}")

        async with httpx.AsyncClient() as client:
            try:
                async with client.stream("POST", self.url, headers=headers, json=payload, timeout=180.0) as response:
                    # 2. Check for Token Rotation in Response Headers
                    header_token = response.headers.get("token") or response.headers.get("Token")
                    
                    # ç”¨äºè¿½è¸ª Token æ›´æ–°
                    token_updated = False
                    new_token_value = None
                    
                    if header_token and header_token != token:
                        logger.info(f"ğŸ”„ [Token] Detected new token in HTTP headers!")
                        logger.info(f"ğŸ”„ [Token] Old: {token[:8]}... -> New: {header_token[:8]}...")
                        await account_manager.update_token(token, header_token)
                        token_updated = True
                        new_token_value = header_token
                    
                    if response.status_code != 200:
                        error_text = await response.aread()
                        logger.error(f"âŒ [Error] Upstream returned status {response.status_code}: {error_text}")
                        if response.status_code == 401 or response.status_code == 403:
                            logger.warning(f"âš ï¸ [Token] Marking token as invalid due to auth error: {token[:8]}...")
                            await account_manager.mark_invalid(token)
                        yield f"data: {json.dumps({'error': f'Upstream error: {response.status_code}'})}\n\n"
                        return

                    chat_id = f"chatcmpl-{uuid.uuid4()}"
                    created_time = int(time.time())
                    
                    # ç”¨äºç´¯ç§¯å†…å®¹
                    content_buffer = ""
                    html_buffer = ""
                    in_html_block = False
                    should_stop = False
                    
                    # ç®€è¦ç­”æ¡ˆç»“æŸæ ‡è®°
                    CONCISE_END_MARKERS = [
                        "# è¯¦ç»†ä¸“ä¸šæŠ¥å‘Š",
                        "æ›´è¯¦ç»†çš„ä¸“ä¸šæŠ¥å‘Šè§ä¸‹æ–‡",
                        "--- æ¨¡å—5.2:",
                        "## 1. æ‰§è¡Œæ‘˜è¦",
                    ]

                    async for chunk in response.aiter_lines():
                        if should_stop:
                            break
                            
                        if not chunk: 
                            continue
                        
                        clean_line = chunk.strip()
                        if clean_line.startswith("data:"):
                            data_content = clean_line[5:].strip()
                            
                            if data_content == "[DONE]":
                                break
                            
                            # è§£æå†…å®¹
                            content_to_process = ""
                            try:
                                json_data = json.loads(data_content)
                                if isinstance(json_data, dict):
                                    # Token æ£€æµ‹
                                    body_token = (
                                        json_data.get("token") or 
                                        json_data.get("Token") or
                                        json_data.get("access_token") or
                                        (json_data.get("data", {}).get("token") if isinstance(json_data.get("data"), dict) else None)
                                    )
                                    
                                    if body_token and body_token != token and not token_updated:
                                        logger.info(f"ğŸ”„ [Token] Detected new token in response body!")
                                        logger.info(f"ğŸ”„ [Token] Old: {token[:8]}... -> New: {body_token[:8]}...")
                                        await account_manager.update_token(token, body_token)
                                        token_updated = True
                                        new_token_value = body_token
                                    
                                    content_to_process = json_data.get("content") or json_data.get("text") or json_data.get("delta") or ""
                                    # è·³è¿‡å…ƒæ•°æ®
                                    if json_data.get("type") in ["conversation", "user-message", "assistant-message"]:
                                        continue
                                else:
                                    content_to_process = str(json_data)
                            except json.JSONDecodeError:
                                content_to_process = data_content
                            
                            if not content_to_process:
                                continue
                            
                            # ç´¯ç§¯åˆ°ç¼“å†²åŒº
                            content_buffer += content_to_process
                            
                            # HTML æ¨¡å¼ï¼šåªæ”¶é›† HTML å†…å®¹
                            if extract_html_only:
                                if "```html" in content_buffer and not in_html_block:
                                    in_html_block = True
                                    # æå– ```html ä¹‹åçš„å†…å®¹
                                    idx = content_buffer.find("```html")
                                    html_buffer = content_buffer[idx + 7:]
                                    content_buffer = ""
                                elif in_html_block:
                                    if "```" in content_to_process and content_to_process.strip().endswith("```"):
                                        # HTML å—ç»“æŸ
                                        html_buffer += content_to_process.replace("```", "")
                                        # è¾“å‡ºå®Œæ•´ HTML
                                        openai_chunk = {
                                            "id": chat_id,
                                            "object": "chat.completion.chunk",
                                            "created": created_time,
                                            "model": model,
                                            "choices": [{"index": 0, "delta": {"content": html_buffer}, "finish_reason": None}]
                                        }
                                        yield f"data: {json.dumps(openai_chunk)}\n\n"
                                        should_stop = True
                                    else:
                                        html_buffer += content_to_process
                                continue
                            
                            # ç®€è¦ç­”æ¡ˆæ¨¡å¼ï¼šæ£€æµ‹æ˜¯å¦åˆ°è¾¾è¯¦ç»†æŠ¥å‘Šéƒ¨åˆ†
                            if stop_at_detailed_report:
                                for marker in CONCISE_END_MARKERS:
                                    if marker in content_buffer:
                                        logger.info(f"ğŸ›‘ [Mode] Detected detailed report marker, stopping stream (concise mode)")
                                        # è¾“å‡º marker ä¹‹å‰çš„å†…å®¹
                                        idx = content_buffer.find(marker)
                                        final_content = content_buffer[:idx]
                                        if final_content.strip():
                                            # è¿‡æ»¤æœ€ç»ˆå†…å®¹
                                            if output_filter:
                                                final_content = output_filter.filter_content(final_content)
                                            if final_content.strip():
                                                openai_chunk = {
                                                    "id": chat_id,
                                                    "object": "chat.completion.chunk",
                                                    "created": created_time,
                                                    "model": model,
                                                    "choices": [{"index": 0, "delta": {"content": final_content}, "finish_reason": None}]
                                                }
                                                yield f"data: {json.dumps(openai_chunk)}\n\n"
                                        should_stop = True
                                        break
                                
                                if should_stop:
                                    break
                            
                            # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„è¡Œå¯ä»¥è¾“å‡º
                            lines = content_buffer.split('\n')
                            
                            if len(lines) > 1:
                                output_text = ""
                                for line in lines[:-1]:
                                    if output_filter:
                                        filtered_line = output_filter.filter_content(line + '\n')
                                        if filtered_line.strip() or filtered_line == '\n':
                                            output_text += filtered_line
                                    else:
                                        output_text += line + '\n'
                                
                                # æ›´æ–°ç¼“å†²åŒº
                                content_buffer = lines[-1]
                                
                                if output_text.strip():
                                    openai_chunk = {
                                        "id": chat_id,
                                        "object": "chat.completion.chunk",
                                        "created": created_time,
                                        "model": model,
                                        "choices": [{"index": 0, "delta": {"content": output_text}, "finish_reason": None}]
                                    }
                                    yield f"data: {json.dumps(openai_chunk)}\n\n"
                    
                    # å¤„ç†å‰©ä½™ç¼“å†²åŒº
                    if content_buffer.strip() and not should_stop and not extract_html_only:
                        if output_filter:
                            content_buffer = output_filter.filter_content(content_buffer)
                        if content_buffer.strip():
                            openai_chunk = {
                                "id": chat_id,
                                "object": "chat.completion.chunk",
                                "created": created_time,
                                "model": model,
                                "choices": [{"index": 0, "delta": {"content": content_buffer}, "finish_reason": None}]
                            }
                            yield f"data: {json.dumps(openai_chunk)}\n\n"
                    
                    # æµç»“æŸï¼Œè®°å½• Token çŠ¶æ€
                    if token_updated:
                        logger.info(f"âœ… [Token] Request completed. Token was updated to: {new_token_value[:8]}...")
                    else:
                        logger.info(f"âœ… [Token] Request completed. Token unchanged: {token[:8]}...")
                    
                    yield "data: [DONE]\n\n"

            except Exception as e:
                logger.error(f"âŒ [Error] Stream error: {e}")
                error_chunk = {"error": str(e)}
                yield f"data: {json.dumps(error_chunk)}\n\n"

